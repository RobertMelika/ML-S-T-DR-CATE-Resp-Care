{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T15:10:32.917195Z",
     "start_time": "2024-06-18T15:10:30.782921Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from econml.metalearners import SLearner, TLearner\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from econml.dr import DRLearner\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T15:10:53.566915Z",
     "start_time": "2024-06-18T15:10:32.918264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../data/bsc_project_set.csv')\n",
    "data = data.drop(['id', 'Unnamed: 0', 'map', 'bilirubin', 'creatinine', 'platelets', 'urea', 'diastolic_blood_pressure'], axis=1)\n",
    "available_columns = ['age','weight','height','pf_ratio','po2','pco2','ph','driving_pressure','lung_compliance','fio2','hco3','heart_rate','minute_volume','peep','plateau_pressure','respiratory_rate','syst_blood_pressure', 'mort_28', 'sex', 'peep_regime']\n",
    "data = data[available_columns]\n",
    "categorical_columns = ['sex', 'peep_regime']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=False)\n",
    "data = data.drop(['sex_F','peep_regime_low'], axis = 1)\n",
    "numeric_columns = data.columns\n",
    "impute_columns = data.columns.difference(['mort_28', 'sex_M', 'peep_regime_high'])\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "# Impute missing data\n",
    "imputer = KNNImputer(n_neighbors=11, weights='uniform')\n",
    "data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Define treatment and outcome columns\n",
    "treatment_column = 'peep_regime_high'\n",
    "outcome_column = 'mort_28'\n",
    "\n",
    "selected_features = ['age', 'weight', 'pf_ratio', 'po2', 'ph', 'fio2', 'driving_pressure', 'plateau_pressure']\n",
    "X = data[selected_features]\n",
    "Y = data[outcome_column]\n",
    "T = data[treatment_column]\n",
    "\n",
    "# Train and save S-learner with Gradient Boosting\n",
    "s_learner_gb = SLearner(overall_model=GradientBoostingRegressor(n_estimators=100, random_state=768))\n",
    "s_learner_gb.fit(Y=Y.astype(int), T=T, X=X)\n",
    "with open('s_learner_gb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(s_learner_gb, f)\n",
    "\n",
    "# Train and save S-learner with Linear Regression\n",
    "s_learner_lr = SLearner(overall_model=LinearRegression())\n",
    "s_learner_lr.fit(Y=Y.astype(int), T=T, X=X)\n",
    "with open('s_learner_lr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(s_learner_lr, f)\n",
    "\n",
    "# Train and save T-learner with Gradient Boosting\n",
    "t_learner_gb = TLearner(models=GradientBoostingRegressor(n_estimators=100, random_state=768))\n",
    "t_learner_gb.fit(Y.astype(int), T=T, X=X)\n",
    "with open('t_learner_gb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(t_learner_gb, f)\n",
    "\n",
    "# Train and save T-learner with Linear Regression\n",
    "t_learner_lr = TLearner(models=LinearRegression())\n",
    "t_learner_lr.fit(Y.astype(int), T=T, X=X)\n",
    "with open('t_learner_lr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(t_learner_lr, f)\n",
    "\n",
    "# Train and save DR-learners with calibrated propensity models\n",
    "def save_dr_learner(dr_learner, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dr_learner, f)\n",
    "\n",
    "# Fit and calibrate propensity models\n",
    "calibrated_propensity_models = {\n",
    "    'svm': CalibratedClassifierCV(SVC(C=1.0, kernel='linear', probability=True, random_state=768), method='isotonic', cv=5),\n",
    "    'logreg': CalibratedClassifierCV(LogisticRegression(C=10.0, solver='lbfgs', random_state=768), method='isotonic', cv=5),\n",
    "    'gb': CalibratedClassifierCV(GradientBoostingClassifier(learning_rate=0.1, max_depth=3, n_estimators=50, random_state=768), method='isotonic', cv=5),\n",
    "    'knn': CalibratedClassifierCV(KNeighborsClassifier(n_neighbors=7), method='isotonic', cv=5)\n",
    "}\n",
    "\n",
    "for name, model in calibrated_propensity_models.items():\n",
    "    model.fit(X, T)\n",
    "    with open(f'calibrated_propensity_model_{name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# DR-learners\n",
    "dr_learners = {\n",
    "    'svm_xgb_xgb': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['svm'],\n",
    "        model_regression=XGBClassifier(learning_rate=0.01, max_depth=3, n_estimators=50, random_state=768),\n",
    "        model_final=XGBRegressor(n_estimators=30, random_state=768),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    ),\n",
    "    'svm_logreg_xgb': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['svm'],\n",
    "        model_regression=LogisticRegression(C=1.0, solver='liblinear', random_state=768),\n",
    "        model_final=XGBRegressor(n_estimators=30, random_state=768),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    ),\n",
    "    'svm_gb_xgb': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['svm'],\n",
    "        model_regression=GradientBoostingClassifier(learning_rate=0.01, max_depth=3, n_estimators=50, random_state=768),\n",
    "        model_final=XGBRegressor(n_estimators=30, random_state=768),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    ),\n",
    "    'logreg_logreg_linear': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['logreg'],\n",
    "        model_regression=LogisticRegression(C=1.0, solver='liblinear', random_state=768),\n",
    "        model_final=LinearRegression(),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    ),\n",
    "    'gb_gb_gb': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['gb'],\n",
    "        model_regression=GradientBoostingClassifier(learning_rate=0.01, max_depth=3, n_estimators=50, random_state=768),\n",
    "        model_final=GradientBoostingRegressor(n_estimators=30, random_state=768),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    ),\n",
    "    'knn_gb_gb': DRLearner(\n",
    "        model_propensity=calibrated_propensity_models['knn'],\n",
    "        model_regression=GradientBoostingClassifier(learning_rate=0.01, max_depth=3, n_estimators=50, random_state=768),\n",
    "        model_final=GradientBoostingRegressor(n_estimators=30, random_state=768),\n",
    "        discrete_outcome=True,\n",
    "        cv=3\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, learner in dr_learners.items():\n",
    "    learner.fit(Y=Y.astype(int), T=T, X=X, W=None)\n",
    "    save_dr_learner(learner, f'dr_learner_{name}.pkl')\n",
    "\n",
    "# Save preprocessing pipeline and column order\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "with open('column_order.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features, f)"
   ],
   "id": "bef95f1de5b6a2a2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
