{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T11:27:50.660791Z",
     "start_time": "2024-06-16T11:27:48.723299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "e853c57e75df8c2",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-16T11:27:52.071677Z",
     "start_time": "2024-06-16T11:27:50.662475Z"
    }
   },
   "source": [
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('../data/bsc_project_set.csv')\n",
    "\n",
    "# Drop id\n",
    "data = data.drop(['id', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "# include peep or not?\n",
    "\n",
    "# Convert categorical data into numeric\n",
    "# 'sex' and 'peep_regime' are categorical, use pd.get_dummies\n",
    "categorical_columns = ['sex', 'peep_regime', 'mort_28']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=False)\n",
    "data = data.drop(['sex_F','peep_regime_low', 'mort_28_True'], axis = 1)\n",
    "\n",
    "\n",
    "numeric_columns = data.columns.difference(['mort_28_False'])\n",
    "impute_columns = data.columns.difference(['mort_28_False', 'sex_M', 'peep_regime_high'])\n",
    "\n",
    "# Normalize data\n",
    "# scaler = StandardScaler()\n",
    "# scaler = Normalizer()\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Impute missing data\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "imputer = KNNImputer(n_neighbors=11, weights='uniform')\n",
    "# Impute using Iterative Imputer\n",
    "# imputer = IterativeImputer(max_iter=10, random_state=768)\n",
    "\n",
    "\n",
    "data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Define treatment and outcome columns\n",
    "treatment_column = 'peep_regime_high'\n",
    "outcome_column = 'mort_28_False'\n",
    "\n",
    "# Define features (excluding treatment and outcome)\n",
    "features = list(set(data.columns) - {treatment_column, outcome_column})\n",
    "\n",
    "X = data[features]\n",
    "Y = data[outcome_column]\n",
    "T = data[treatment_column]\n",
    "\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:38.605773Z",
     "start_time": "2024-06-13T12:10:36.296885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Outcome\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=768)\n",
    "\n",
    "\n",
    "rf = GradientBoostingClassifier(n_estimators=100, random_state=768)\n",
    "# rf = LogisticRegression(random_state=768)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(feature_importance_df['feature'], feature_importance_df['importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance for Predicting Outcome')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(f\"plots/features/outcome_predictors_peep.png\")\n",
    "plt.savefig(f\"plots/features/outcome_predictors_peep.svg\")\n",
    "plt.show()\n"
   ],
   "id": "bd93ffdee12b41b2",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:38.608997Z",
     "start_time": "2024-06-13T12:10:38.606902Z"
    }
   },
   "cell_type": "code",
   "source": "# X = X.drop(['peep'], axis=1)",
   "id": "a0ab6ad37f6956a7",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:41.015439Z",
     "start_time": "2024-06-13T12:10:38.610568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treatment\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T, test_size=0.2, random_state=768)\n",
    "\n",
    "\n",
    "rf_treatment = GradientBoostingClassifier(n_estimators=100, random_state=768)\n",
    "# rf = LogisticRegression(random_state=768)\n",
    "rf_treatment.fit(X_train, y_train)\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "# Feature importance\n",
    "importances_treatment = rf_treatment.feature_importances_\n",
    "feature_importance_treatment_df = pd.DataFrame({'feature': feature_names, 'importance': importances_treatment})\n",
    "feature_importance_treatment_df = feature_importance_treatment_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance for treatment\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(feature_importance_treatment_df['feature'], feature_importance_treatment_df['importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance for Predicting Treatment')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(f\"plots/features/treatment_predictors_peep.png\")\n",
    "plt.savefig(f\"plots/features/treatment_predictors_peep.svg\")\n",
    "plt.show()\n"
   ],
   "id": "3343e21bf7b4cc55",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:41.019542Z",
     "start_time": "2024-06-13T12:10:41.016315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine top features\n",
    "top_features_outcome = set(feature_importance_df.head(10)['feature'])\n",
    "top_features_treatment = set(feature_importance_treatment_df.head(10)['feature'])\n",
    "\n",
    "# Identify potential confounders\n",
    "potential_confounders = top_features_outcome.intersection(top_features_treatment)\n",
    "print(f'Potential Confounders: {potential_confounders}')\n"
   ],
   "id": "337efe2ee0b61856",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:41.038020Z",
     "start_time": "2024-06-13T12:10:41.020480Z"
    }
   },
   "cell_type": "code",
   "source": "X = X.drop(['peep'], axis=1)",
   "id": "92f8fd309c41c7be",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:43.085376Z",
     "start_time": "2024-06-13T12:10:41.040965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Outcome\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=768)\n",
    "\n",
    "\n",
    "rf = GradientBoostingClassifier(n_estimators=100, random_state=768)\n",
    "# rf = LogisticRegression(random_state=768)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(feature_importance_df['feature'], feature_importance_df['importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance for Predicting Outcome')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(f\"plots/features/outcome_predictors_no_peep.png\")\n",
    "plt.savefig(f\"plots/features/outcome_predictors_no_peep.svg\")\n",
    "plt.show()\n"
   ],
   "id": "4547d69e28e6ad7d",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:45.114733Z",
     "start_time": "2024-06-13T12:10:43.086584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Treatment\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, T, test_size=0.2, random_state=768)\n",
    "\n",
    "\n",
    "rf_treatment = GradientBoostingClassifier(n_estimators=100, random_state=768)\n",
    "# rf = LogisticRegression(random_state=768)\n",
    "rf_treatment.fit(X_train, y_train)\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "# Feature importance\n",
    "importances_treatment = rf_treatment.feature_importances_\n",
    "feature_importance_treatment_df = pd.DataFrame({'feature': feature_names, 'importance': importances_treatment})\n",
    "feature_importance_treatment_df = feature_importance_treatment_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plotting feature importance for treatment\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.barh(feature_importance_treatment_df['feature'], feature_importance_treatment_df['importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance for Predicting Treatment')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(f\"plots/features/treatment_predictors_no_peep.png\")\n",
    "plt.savefig(f\"plots/features/treatment_predictors_no_peep.svg\")\n",
    "plt.show()\n"
   ],
   "id": "83e178ba69863fbc",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:10:45.121715Z",
     "start_time": "2024-06-13T12:10:45.116130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine top features\n",
    "top_features_outcome = set(feature_importance_df.head(10)['feature'])\n",
    "top_features_treatment = set(feature_importance_treatment_df.head(10)['feature'])\n",
    "\n",
    "# Identify potential confounders\n",
    "potential_confounders = top_features_outcome.intersection(top_features_treatment)\n",
    "print(f'Potential Confounders: {potential_confounders}')\n"
   ],
   "id": "576883b5f730edb5",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T11:32:13.261681Z",
     "start_time": "2024-06-16T11:32:13.252826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count total people in each group\n",
    "total_high_peep = data[treatment_column].sum()\n",
    "total_low_peep = len(data) - total_high_peep\n",
    "\n",
    "# Count total people who survived and died\n",
    "total_survived = data[outcome_column].sum()\n",
    "total_died = len(data) - total_survived\n",
    "\n",
    "# Count people who got high peep and survived or died\n",
    "high_peep_survived = data[(data[treatment_column] == 1) & (data[outcome_column] == 1)].shape[0]\n",
    "high_peep_died = data[(data[treatment_column] == 1) & (data[outcome_column] == 0)].shape[0]\n",
    "\n",
    "# Count people who got low peep and survived or died\n",
    "low_peep_survived = data[(data[treatment_column] == 0) & (data[outcome_column] == 1)].shape[0]\n",
    "low_peep_died = data[(data[treatment_column] == 0) & (data[outcome_column] == 0)].shape[0]\n",
    "\n",
    "# Calculate percentages\n",
    "pct_high_peep = total_high_peep / len(data) * 100\n",
    "pct_low_peep = total_low_peep / len(data) * 100\n",
    "pct_survived = total_survived / len(data) * 100\n",
    "pct_died = total_died / len(data) * 100\n",
    "pct_high_peep_survived = high_peep_survived / total_high_peep * 100\n",
    "pct_high_peep_died = high_peep_died / total_high_peep * 100\n",
    "pct_low_peep_survived = low_peep_survived / total_low_peep * 100\n",
    "pct_low_peep_died = low_peep_died / total_low_peep * 100\n",
    "\n",
    "# Print the results with percentages\n",
    "print(f\"Total people who got high PEEP: {total_high_peep} ({pct_high_peep:.2f}%)\")\n",
    "print(f\"Total people who got low PEEP: {total_low_peep} ({pct_low_peep:.2f}%)\")\n",
    "print(f\"Total people who survived: {total_survived} ({pct_survived:.2f}%)\")\n",
    "print(f\"Total people who died: {total_died} ({pct_died:.2f}%)\")\n",
    "print(f\"Total people who got high PEEP and survived: {high_peep_survived} ({pct_high_peep_survived:.2f}%)\")\n",
    "print(f\"Total people who got high PEEP and died: {high_peep_died} ({pct_high_peep_died:.2f}%)\")\n",
    "print(f\"Total people who got low PEEP and survived: {low_peep_survived} ({pct_low_peep_survived:.2f}%)\")\n",
    "print(f\"Total people who got low PEEP and died: {low_peep_died} ({pct_low_peep_died:.2f}%)\")"
   ],
   "id": "f78dc1f9da9b1efc",
   "execution_count": 7,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
