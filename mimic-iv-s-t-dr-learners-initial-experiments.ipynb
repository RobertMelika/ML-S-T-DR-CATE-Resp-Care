{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-22T13:07:09.945435Z",
     "start_time": "2024-05-22T13:07:09.940937Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from econml.metalearners import SLearner\n",
    "from econml.metalearners import TLearner\n",
    "from econml.dr import DRLearner\n",
    "from econml.dr import LinearDRLearner\n",
    "from econml.dr import SparseLinearDRLearner\n",
    "from econml.dr import ForestDRLearner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "from nb21 import cumulative_gain, elast\n",
    "from catenets.models.jax import SNet, TNet, DRNet\n",
    "\n",
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "import shap\n",
    "from econml.dml import LinearDML"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6ad3c005e461c0",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:07:10.137797Z",
     "start_time": "2024-05-22T13:07:10.134779Z"
    }
   },
   "cell_type": "code",
   "source": "# pd.read_csv('../data/bsc_project_set.csv')",
   "id": "2e383c6667ed4d11",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b3624bd9cd4c0ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:07:31.292100Z",
     "start_time": "2024-05-22T13:07:10.191031Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('../data/bsc_project_set.csv')\n",
    "\n",
    "# Drop id\n",
    "data = data.drop(['id', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "\n",
    "# Convert categorical data into numeric\n",
    "# 'sex' and 'peep_regime' are categorical, use pd.get_dummies\n",
    "categorical_columns = ['sex', 'peep_regime']\n",
    "data = pd.get_dummies(data, columns=categorical_columns, drop_first=False)\n",
    "data = data.drop(['sex_F','peep_regime_low'], axis = 1)\n",
    "\n",
    "\n",
    "numeric_columns = data.columns.difference(['mort_28'])\n",
    "impute_columns = data.columns.difference(['mort_28', 'sex_M', 'peep_regime_high'])\n",
    "\n",
    "# Normalize data\n",
    "# scaler = StandardScaler()\n",
    "# scaler = Normalizer()\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Impute missing data\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "# Impute using Iterative Imputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=768)\n",
    "\n",
    "\n",
    "data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Define treatment and outcome columns\n",
    "treatment_column = 'peep_regime_high'\n",
    "outcome_column = 'mort_28'\n",
    "\n",
    "# Define features (excluding treatment and outcome)\n",
    "features = list(set(data.columns) - {treatment_column, outcome_column})\n",
    "\n",
    "# Confounding variables\n",
    "confounders = ['age', 'sex_M', 'weight', 'height', 'pf_ratio', 'po2', 'fio2', 'heart_rate']\n",
    "\n",
    "# print(data.shape)\n",
    "\n",
    "X = data[features]\n",
    "Y = data[outcome_column]\n",
    "T = data[treatment_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = train_test_split(\n",
    "    data[features], data[outcome_column], data[treatment_column], test_size=0.2, random_state=768)\n",
    "\n",
    "\n",
    "\n",
    "# t_train = data.loc[X_train.index, treatment_column]\n",
    "# t_test = data.loc[X_test.index, treatment_column]\n",
    "\n",
    "# print(t_train.shape, t_test.shape)\n",
    "# print(X_train.shape, X_test.shape)\n",
    "# print(y_train.shape, y_test.shape)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8313db6310889aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:07:31.304987Z",
     "start_time": "2024-05-22T13:07:31.298247Z"
    }
   },
   "source": [
    "# print(data)\n",
    "\n",
    "y_train_nn = y_train.values\n",
    "y_test_nn = y_test.values\n",
    "t_train_nn = t_train.values\n",
    "t_test_nn = t_test.values\n",
    "X_train_nn = X_train.values\n",
    "X_test_nn = X_test.values"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "69f905ff430d7125",
   "metadata": {},
   "source": [
    "S-Learner"
   ]
  },
  {
   "cell_type": "code",
   "id": "aee20b012e2c54f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:22.219687Z",
     "start_time": "2024-05-22T13:07:31.307094Z"
    }
   },
   "source": [
    "\n",
    "# S-Learner with Random Forest\n",
    "s_learner_rf = SLearner(overall_model=RandomForestRegressor(n_estimators=100, random_state=768))\n",
    "print(\"S-Learner Random Forest training\")\n",
    "s_learner_rf.fit(Y=y_train.astype(int), T=t_train, X=X_train)\n",
    "\n",
    "# S-Learner with Gradient Boosting\n",
    "s_learner_gb = SLearner(overall_model=GradientBoostingRegressor(n_estimators=100, random_state=768))\n",
    "print(\"S-Learner Gradient Boosting training\")\n",
    "s_learner_gb.fit(Y=y_train.astype(int), T=t_train, X=X_train)\n",
    "\n",
    "# S-Learner with Linear Regression\n",
    "s_learner_lr = SLearner(overall_model=LinearRegression())\n",
    "print(\"S-Learner Linear Regression training\")\n",
    "s_learner_lr.fit(Y=y_train.astype(int), T=t_train, X=X_train)\n",
    "\n",
    "# # S-Learner with SVMs\n",
    "# s_learner_svm = SLearner(overall_model=SVR())\n",
    "# print(\"S-Learner SVM training\")\n",
    "# s_learner_svm.fit(Y=y_train.astype(int), T=t_train, X=X_train)\n",
    "\n",
    "# S-Learner with Neural Networks\n",
    "s_learner_nn = SNet(binary_y=True)\n",
    "print(\"S-Learner Neural Network training\")\n",
    "s_learner_nn.fit(y=y_train_nn.astype(int), w=t_train_nn, X=X_train_nn)\n",
    "\n",
    "# Estimate CATE for each learner\n",
    "cate_s_learner_rf = s_learner_rf.effect(X_test)\n",
    "# mse_s_learner_rf = mean_squared_error(y_test, cate_s_learner_rf)\n",
    "cate_s_learner_gb = s_learner_gb.effect(X_test)\n",
    "# mse_s_learner_gb = mean_squared_error(y_test, cate_s_learner_gb)\n",
    "cate_s_learner_lr = s_learner_lr.effect(X_test)\n",
    "\n",
    "# cate_s_learner_svm = s_learner_svm.effect(X_test)\n",
    "cate_s_learner_nn = s_learner_nn.predict(X_test)\n",
    "\n",
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Random Forest - Mean CATE:\", np.mean(cate_s_learner_rf), \"Std Dev:\", np.std(cate_s_learner_rf))\n",
    "print(\"S-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_s_learner_gb), \"Std Dev:\", np.std(cate_s_learner_gb))\n",
    "print(\"S-Learner - Linear Regression - Mean CATE:\", np.mean(cate_s_learner_lr), \"Std Dev:\", np.std(cate_s_learner_lr))\n",
    "# print(\"S-Learner - Linear Regression - Mean CATE:\", np.mean(cate_s_learner_svm), \"Std Dev:\", np.std(cate_s_learner_svm))\n",
    "print(\"S-Learner - Neural Networks - Mean CATE:\", np.mean(cate_s_learner_nn), \"Std Dev:\", np.std(cate_s_learner_nn))"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "49403b4ad376f3b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:23.445487Z",
     "start_time": "2024-05-22T13:08:22.221254Z"
    }
   },
   "source": [
    "# Estimate CATE on the train set?\n",
    "cate_s_learner_rf_train = s_learner_rf.effect(X_train)\n",
    "cate_s_learner_gb_train = s_learner_gb.effect(X_train)\n",
    "cate_s_learner_lr_train = s_learner_lr.effect(X_train)\n",
    "cate_s_learner_nn_train = s_learner_nn.predict(X_train)\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_s_rf_train = cumulative_gain(train_data.assign(cate=cate_s_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_rf_test = cumulative_gain(test_data.assign(cate=cate_s_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_s_gb_train = cumulative_gain(train_data.assign(cate=cate_s_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_gb_test = cumulative_gain(test_data.assign(cate=cate_s_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_s_lr_train = cumulative_gain(train_data.assign(cate=cate_s_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_lr_test = cumulative_gain(test_data.assign(cate=cate_s_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_s_nn_train = cumulative_gain(train_data.assign(cate=cate_s_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_nn_test = cumulative_gain(test_data.assign(cate=cate_s_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_s_rf_test, color=\"C0\", label=\"S-Learner Test - Random Forest\")\n",
    "plt.plot(gain_curve_s_rf_train, color=\"C1\", label=\"S-Learner Train - Random Forest\")\n",
    "plt.plot(gain_curve_s_gb_test, color=\"C2\", label=\"S-Learner Test - Gradient Boosting\")\n",
    "plt.plot(gain_curve_s_gb_train, color=\"C3\", label=\"S-Learner Train - Gradient Boosting\")\n",
    "plt.plot(gain_curve_s_lr_test, color=\"C4\", label=\"S-Learner Test - Linear Regression\")\n",
    "plt.plot(gain_curve_s_lr_train, color=\"C5\", label=\"S-Learner Train - Linear Regression\")\n",
    "plt.plot(gain_curve_s_nn_test, color=\"C6\", label=\"S-Learner Test - Neural Network\")\n",
    "plt.plot(gain_curve_s_nn_train, color=\"C7\", label=\"S-Learner Train - Neural Network\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain\")\n",
    "plt.savefig(f\"plots/mimic/S-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/S-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:24.225336Z",
     "start_time": "2024-05-22T13:08:23.446383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Mean CATE:\", np.mean(cate_s_learner_rf), \"Std Dev:\", np.std(cate_s_learner_rf))\n",
    "print(\"S-Learner - Mean CATE:\", np.mean(cate_s_learner_gb), \"Std Dev:\", np.std(cate_s_learner_gb))\n",
    "print(\"S-Learner - Mean CATE:\", np.mean(cate_s_learner_lr), \"Std Dev:\", np.std(cate_s_learner_lr))\n",
    "print(\"S-Learner - Mean CATE:\", np.mean(cate_s_learner_nn), \"Std Dev:\", np.std(cate_s_learner_nn))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_s_learner_rf, 'o', label='S-Learner - Random Forest')\n",
    "plt.plot(cate_s_learner_gb, 'x', label='S-Learner - Gradient Boosting')\n",
    "plt.plot(cate_s_learner_lr, '+', label='S-Learner - Linear Regression')\n",
    "plt.plot(cate_s_learner_nn, '*', label='S-Learner - Neural Network')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: S-Learner using: Random Forest, Gradient Boosting, Linear Regression')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/S-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/S-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "bff26c0c103c3347",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "44677368d1cf5ebd",
   "metadata": {},
   "source": [
    "T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "id": "b6271806e9dc0c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:38.371667Z",
     "start_time": "2024-05-22T13:08:24.226386Z"
    }
   },
   "source": [
    "# T-Learner with Random Forest\n",
    "t_learner_rf = TLearner(models=RandomForestRegressor(n_estimators=100, random_state=768))\n",
    "print(\"T-Learner Random Forest training\")\n",
    "t_learner_rf.fit(y_train.astype(int), X=X_train, T=t_train)\n",
    "\n",
    "# T-Learner with Gradient Boosting\n",
    "t_learner_gb = TLearner(models=GradientBoostingRegressor(n_estimators=100, random_state=768))\n",
    "print(\"T-Learner Gradient Boosting training\")\n",
    "t_learner_gb.fit(y_train.astype(int), X=X_train, T=t_train)\n",
    "\n",
    "# T-Learner with Linear Regression\n",
    "t_learner_lr = TLearner(models=LinearRegression())\n",
    "print(\"T-Learner Linear Regression training\")\n",
    "t_learner_lr.fit(y_train.astype(int), X=X_train, T=t_train)\n",
    "\n",
    "# T-Learner with SVMs\n",
    "# t_learner_svm = TLearner(models=SVR())\n",
    "# print(\"T-Learner SVM training\")\n",
    "# t_learner_lr.fit(y_train.astype(int), X=X_train, T=t_train)\n",
    "\n",
    "\n",
    "#  T-Learner with Neural Networks\n",
    "t_learner_nn = TNet(binary_y=True)\n",
    "print(\"T-Learner Neural Network training\")\n",
    "# t_learner_nn.fit(y=y_train.astype(int), X=X_train, T=t_train)\n",
    "t_learner_nn.fit(y=y_train_nn.astype(int), w=t_train_nn, X=X_train_nn)\n",
    "\n",
    "\n",
    "cate_t_learner_rf = t_learner_rf.effect(X_test)\n",
    "# mse_t_learner_rf = mean_squared_error(y_test, cate_t_learner_rf)\n",
    "\n",
    "cate_t_learner_gb = t_learner_gb.effect(X_test)\n",
    "# mse_t_learner_gb = mean_squared_error(y_test, cate_t_learner_rf)\n",
    "\n",
    "cate_t_learner_lr = t_learner_lr.effect(X_test)\n",
    "\n",
    "# cate_t_learner_svm = t_learner_svm.effect(X_test)\n",
    "\n",
    "cate_t_learner_nn = t_learner_nn.predict(X_test)\n",
    "\n",
    "print(\"T-Learner - Random Forest - Mean CATE:\", np.mean(cate_t_learner_rf), \"Std Dev:\", np.std(cate_t_learner_rf))\n",
    "print(\"T-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_t_learner_rf), \"Std Dev:\", np.std(cate_t_learner_rf))\n",
    "print(\"T-Learner - Linear Regression - Mean CATE:\", np.mean(cate_t_learner_lr), \"Std Dev:\", np.std(cate_t_learner_lr))\n",
    "# print(\"T-Learner - SVM - Mean CATE:\", np.mean(cate_t_learner_svm), \"Std Dev:\", np.std(cate_t_learner_svm))\n",
    "print(\"T-Learner - Neural Networks - Mean CATE:\", np.mean(cate_t_learner_nn), \"Std Dev:\", np.std(cate_t_learner_nn))"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:38.375766Z",
     "start_time": "2024-05-22T13:08:38.372856Z"
    }
   },
   "cell_type": "code",
   "source": "# print(cate_t_learner_nn)",
   "id": "361cf5cef30cc317",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:39.264568Z",
     "start_time": "2024-05-22T13:08:38.377216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estimate CATE on the train set?\n",
    "cate_t_learner_rf_train = t_learner_rf.effect(X_train)\n",
    "cate_t_learner_gb_train = t_learner_gb.effect(X_train)\n",
    "cate_t_learner_lr_train = t_learner_lr.effect(X_train)\n",
    "# cate_t_learner_svm_train = t_learner_svm.effect(X_train)\n",
    "cate_t_learner_nn_train = t_learner_nn.predict(X_train)\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_t_rf_train = cumulative_gain(train_data.assign(cate=cate_t_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_rf_test = cumulative_gain(test_data.assign(cate=cate_t_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_gb_train = cumulative_gain(train_data.assign(cate=cate_t_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_gb_test = cumulative_gain(test_data.assign(cate=cate_t_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_lr_train = cumulative_gain(train_data.assign(cate=cate_t_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_lr_test = cumulative_gain(test_data.assign(cate=cate_t_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "# gain_curve_t_svm_train = cumulative_gain(train_data.assign(cate=cate_t_learner_svm_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "# gain_curve_t_svm_test = cumulative_gain(test_data.assign(cate=cate_t_learner_svm), \"cate\", y=outcome_column, t=treatment_column)\n",
    " \n",
    "\n",
    "gain_curve_t_nn_train = cumulative_gain(train_data.assign(cate=cate_t_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_nn_test = cumulative_gain(test_data.assign(cate=cate_t_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_t_rf_test, color=\"C0\", label=\"T-Learner Test - Random Forest\")\n",
    "plt.plot(gain_curve_t_rf_train, color=\"C1\", label=\"T-Learner Train - Random Forest\")\n",
    "plt.plot(gain_curve_t_gb_test, color=\"C2\", label=\"T-Learner Test - Gradient Boosting\")\n",
    "plt.plot(gain_curve_t_gb_train, color=\"C3\", label=\"T-Learner Train - Gradient Boosting\")\n",
    "plt.plot(gain_curve_t_lr_test, color=\"C4\", label=\"T-Learner Test - Linear Regression\")\n",
    "plt.plot(gain_curve_t_lr_train, color=\"C5\", label=\"T-Learner Train - Linear Regression\")\n",
    "# plt.plot(gain_curve_t_svm_test, color=\"C6\", label=\"T-Learner Test - SVM\")\n",
    "# plt.plot(gain_curve_t_svm_train, color=\"C7\", label=\"T-Learner Train - SVM\")\n",
    "plt.plot(gain_curve_t_nn_test, color=\"C6\", label=\"T-Learner Test - Neural Network\")\n",
    "plt.plot(gain_curve_t_nn_train, color=\"C7\", label=\"T-Learner Train - Neural Network\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain\")\n",
    "plt.savefig(f\"plots/mimic/T-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/T-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "5f402a7b19fd0b5c",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:08:39.739647Z",
     "start_time": "2024-05-22T13:08:39.265665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"T-Learner - Mean CATE:\", np.mean(cate_t_learner_rf), \"Std Dev:\", np.std(cate_t_learner_rf))\n",
    "print(\"T-Learner - Mean CATE:\", np.mean(cate_t_learner_gb), \"Std Dev:\", np.std(cate_t_learner_gb))\n",
    "print(\"T-Learner - Mean CATE:\", np.mean(cate_t_learner_lr), \"Std Dev:\", np.std(cate_t_learner_lr))\n",
    "print(\"T-Learner - Mean CATE:\", np.mean(cate_t_learner_nn), \"Std Dev:\", np.std(cate_t_learner_nn))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_t_learner_rf, 'o', label='T-Learner - Random Forest')\n",
    "plt.plot(cate_t_learner_gb, 'x', label='T-Learner - Gradient Boosting')\n",
    "plt.plot(cate_t_learner_lr, '+', label='T-Learner - Linear Regression')\n",
    "plt.plot(cate_t_learner_nn, '*', label='T-Learner - Neural Network')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: T-Learner using: Random Forest, Gradient Boosting, Linear Regression')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/T-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/T-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "839e2b9cb9a5bdb5",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4b7c119e9e8246",
   "metadata": {},
   "source": [
    "DR-learner"
   ]
  },
  {
   "cell_type": "code",
   "id": "7ef04cca927ca03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:00.461857Z",
     "start_time": "2024-05-22T13:08:39.742115Z"
    }
   },
   "source": [
    "# DR-Learner with Random Forest for regression and logistic regression for propensity\n",
    "# dr_learner = LinearDRLearner(\n",
    "#     model_regression=RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "#     model_propensity=LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "#     cv=3,\n",
    "# )\n",
    "# dr_learner = LinearDRLearner(\n",
    "#     model_regression=RandomForestRegressor(n_estimators=100, random_state=768),\n",
    "#     model_propensity=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# )\n",
    "\n",
    "\n",
    "features_without_confounders = list(set(features) - set(confounders))\n",
    "\n",
    "# DR-Learner with Random Forest for regression and for propensity\n",
    "dr_learner_rf = DRLearner(\n",
    "    model_propensity=RandomForestClassifier(random_state=768), \n",
    "    model_regression=RandomForestClassifier(random_state=768),\n",
    "    model_final=LinearRegression(),\n",
    "    discrete_outcome=True\n",
    ")\n",
    "print(\"DR-Learner Random Forest training\")\n",
    "dr_learner_rf.fit(y_train.astype(int), t_train, X=X_train[features_without_confounders], W=X_train[confounders])\n",
    "\n",
    "# DR-Learner with Gradient Boosting for regression and for propensity\n",
    "dr_learner_gb = DRLearner(\n",
    "    model_propensity=GradientBoostingClassifier(random_state=768), \n",
    "    model_regression=GradientBoostingClassifier(random_state=768),\n",
    "    model_final=LinearRegression(),\n",
    "    discrete_outcome=True\n",
    ")\n",
    "print(\"DR-Learner Gradient Boosting training\")\n",
    "dr_learner_gb.fit(y_train.astype(int), t_train, X=X_train[features_without_confounders], W=X_train[confounders])\n",
    "\n",
    "# DR-Learner with Logistic Regression for regression and propensity\n",
    "dr_learner_lr = DRLearner(\n",
    "    model_propensity=LogisticRegression(random_state=768), \n",
    "    model_regression=LogisticRegression(random_state=768),\n",
    "    model_final=LinearRegression(),\n",
    "    discrete_outcome=True\n",
    ")\n",
    "print(\"DR-Learner Logistic Regression training\")\n",
    "dr_learner_lr.fit(y_train.astype(int), t_train, X=X_train[features_without_confounders], W=X_train[confounders])\n",
    "\n",
    "# # DR-Learner with Support Vector Machines for regression and propensity\n",
    "# dr_learner_svm = DRLearner(\n",
    "#     model_propensity=SVC(random_state=768), \n",
    "#     model_regression=SVC(random_state=768),\n",
    "#     model_final=SVR(),\n",
    "#     discrete_outcome=True\n",
    "# )\n",
    "# print(\"DR-Learner SVM training\")\n",
    "# dr_learner_svm.fit(y_train.astype(int), t_train, X=X_train[features_without_confounders], W=X_train[confounders])\n",
    "\n",
    "\n",
    "# DR-Learner with Neural Networks\n",
    "dr_learner_nn = DRNet(binary_y=True)\n",
    "print(\"DR-Learner Neural Network training\")\n",
    "# t_learner_nn.fit(y=y_train.astype(int), X=X_train, T=t_train)\n",
    "dr_learner_nn.fit(y=y_train_nn.astype(int), w=t_train_nn, X=X_train_nn)\n",
    "\n",
    "cate_dr_learner_rf = dr_learner_rf.effect(X_test[features_without_confounders])\n",
    "\n",
    "cate_dr_learner_gb = dr_learner_gb.effect(X_test[features_without_confounders])\n",
    "# mse_dr_learner_gb = mean_squared_error(y_test, cate_dr_learner_gb)\n",
    "\n",
    "cate_dr_learner_lr = dr_learner_lr.effect(X_test[features_without_confounders])\n",
    "\n",
    "# cate_dr_learner_svm = dr_learner_svm.effect(X_test[features_without_confounders])\n",
    "\n",
    "cate_dr_learner_nn = dr_learner_nn.predict(X_test)\n",
    "\n",
    "print(\"DR-Learner - Random Forest - Mean CATE\", np.mean(cate_dr_learner_rf), \"Std Dev:\", np.std(cate_dr_learner_rf))\n",
    "print(\"DR-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_dr_learner_gb), \"Std Dev:\", np.std(cate_dr_learner_gb))\n",
    "print(\"DR-Learner - Logistic Regression - Mean CATE:\", np.mean(cate_dr_learner_lr), \"Std Dev:\", np.std(cate_dr_learner_lr))\n",
    "# print(\"DR-Learner - SVM - Mean CATE:\", np.mean(cate_dr_learner_svm), \"Std Dev:\", np.std(cate_dr_learner_svm))\n",
    "print(\"DR-Learner - Neural Networks - Mean CATE:\", np.mean(cate_dr_learner_nn), \"Std Dev:\", np.std(cate_dr_learner_nn))\n",
    "\n",
    "# # Define models for DR-Learner\n",
    "# outcome_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# propensity_model = LogisticRegression()\n",
    "# \n",
    "# # DR-Learner instance\n",
    "# dr_learner = LinearDRLearner(\n",
    "#     model_regression=outcome_model,\n",
    "#     model_propensity=propensity_model,\n",
    "#     cv=3,\n",
    "# )\n",
    "\n"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:11:21.088699Z",
     "start_time": "2024-05-22T14:11:21.059085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Estimate CATE on the train set?\n",
    "cate_dr_learner_rf_train = dr_learner_rf.effect(X_train[features_without_confounders])\n",
    "cate_dr_learner_gb_train = dr_learner_gb.effect(X_train[features_without_confounders])\n",
    "cate_dr_learner_lr_train = dr_learner_lr.effect(X_train[features_without_confounders])\n",
    "cate_dr_learner_nn_train = dr_learner_nn.predict(X_train)\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_dr_rf_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_rf_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_gb_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_gb_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_lr_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_lr_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_nn_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_nn_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "# plt.plot(gain_curve_dr_rf_test, color=\"C0\", label=\"DR-Learner Test - Random Forest\")\n",
    "# plt.plot(gain_curve_dr_rf_train, color=\"C1\", label=\"DR-Learner Train - Random Forest\")\n",
    "plt.plot(gain_curve_dr_gb_test, color=\"C2\", label=\"DR-Learner Test - Gradient Boosting\")\n",
    "plt.plot(gain_curve_dr_gb_train, color=\"C3\", label=\"DR-Learner Train - Gradient Boosting\")\n",
    "plt.plot(gain_curve_dr_lr_test, color=\"C4\", label=\"DR-Learner Test - Logistic Regression\")\n",
    "plt.plot(gain_curve_dr_lr_train, color=\"C5\", label=\"DR-Learner Train - Logistic Regression\")\n",
    "plt.plot(gain_curve_dr_nn_test, color=\"C6\", label=\"DR-Learner Test - Neural Network\")\n",
    "plt.plot(gain_curve_dr_nn_train, color=\"C7\", label=\"DR-Learner Train - Neural Network\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain\")\n",
    "plt.savefig(f\"plots/mimic/DR-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/DR-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "cde5228a7a4dc7ed",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:01.973377Z",
     "start_time": "2024-05-22T13:09:01.356464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"DR-Learner - Mean CATE:\", np.mean(cate_dr_learner_rf), \"Std Dev:\", np.std(cate_dr_learner_rf))\n",
    "print(\"DR-Learner - Mean CATE:\", np.mean(cate_dr_learner_gb), \"Std Dev:\", np.std(cate_dr_learner_gb))\n",
    "print(\"DR-Learner - Mean CATE:\", np.mean(cate_dr_learner_lr), \"Std Dev:\", np.std(cate_dr_learner_lr))\n",
    "print(\"DR-Learner - Mean CATE:\", np.mean(cate_dr_learner_nn), \"Std Dev:\", np.std(cate_dr_learner_nn))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "# plt.plot(cate_dr_learner_rf, 'o', label='DR-Learner - Random Forest')\n",
    "plt.plot(cate_dr_learner_gb, 'x', label='DR-Learner - Gradient Boosting')\n",
    "plt.plot(cate_dr_learner_lr, '+', label='DR-Learner - Logistic Regression')\n",
    "plt.plot(cate_dr_learner_nn, '*', label='DR-Learner - Neural Network')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: DR-Learner using: Random Forest, Gradient Boosting, Logistic Regression')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/DR-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/DR-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "59abbe9216acfddb",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Linear CATEs comparison",
   "id": "2d74b8fdc95c8bbe"
  },
  {
   "cell_type": "code",
   "id": "56b03c71f0cc532b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:02.385012Z",
     "start_time": "2024-05-22T13:09:01.974327Z"
    }
   },
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Linear Regression - Mean CATE:\", np.mean(cate_s_learner_lr), \"Std Dev:\", np.std(cate_s_learner_lr))\n",
    "print(\"T-Learner - Linear Regression - Mean CATE:\", np.mean(cate_t_learner_lr), \"Std Dev:\", np.std(cate_t_learner_lr))\n",
    "print(\"DR-Learner - Logistic Regression - Mean CATE:\", np.mean(cate_dr_learner_lr), \"Std Dev:\", np.std(cate_dr_learner_lr))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_s_learner_lr, 'o', label='S-Learner')\n",
    "plt.plot(cate_t_learner_lr, 'x', label='T-Learner')\n",
    "plt.plot(cate_dr_learner_lr, '+', label='DR-Learner')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: Linear and Logistic Regression: S-Learner, T-Learner, DR-Learner')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/LR-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/LR-CATEs.svg\")\n",
    "plt.show()"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ad45ef610759da22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:04.065052Z",
     "start_time": "2024-05-22T13:09:02.386639Z"
    }
   },
   "source": [
    "# Estimate CATE on the train set?\n",
    "cate_s_learner_lr_train = s_learner_lr.effect(X_train)\n",
    "cate_t_learner_lr_train = t_learner_lr.effect(X_train)\n",
    "cate_dr_learner_lr_train = dr_learner_lr.effect(X_train[features_without_confounders])\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_s_lr_train = cumulative_gain(train_data.assign(cate=cate_s_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_lr_test = cumulative_gain(test_data.assign(cate=cate_s_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_lr_train = cumulative_gain(train_data.assign(cate=cate_t_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_lr_test = cumulative_gain(test_data.assign(cate=cate_t_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_lr_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_lr_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_s_lr_test, color=\"C0\", label=\"S-Learner Test\")\n",
    "plt.plot(gain_curve_s_lr_train, color=\"C1\", label=\"S-Learner Train\")\n",
    "plt.plot(gain_curve_t_lr_test, color=\"C2\", label=\"T-Learner Test\")\n",
    "plt.plot(gain_curve_t_lr_train, color=\"C3\", label=\"T-Learner Train\")\n",
    "plt.plot(gain_curve_dr_lr_test, color=\"C4\", label=\"DR-Learner Test\")\n",
    "plt.plot(gain_curve_dr_lr_train, color=\"C5\", label=\"DR-Learner Train\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain - Linear and Logistic Regression comparison\")\n",
    "plt.savefig(f\"plots/mimic/LR-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/LR-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest CATEs comparison",
   "id": "84b626b72e0641e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:04.557571Z",
     "start_time": "2024-05-22T13:09:04.066619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Random Forest - Mean CATE:\", np.mean(cate_s_learner_rf), \"Std Dev:\", np.std(cate_s_learner_rf))\n",
    "print(\"T-Learner - Random Forest - Mean CATE:\", np.mean(cate_t_learner_rf), \"Std Dev:\", np.std(cate_t_learner_rf))\n",
    "print(\"DR-Learner - Random Forest - Mean CATE:\", np.mean(cate_dr_learner_rf), \"Std Dev:\", np.std(cate_dr_learner_rf))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_s_learner_rf, 'o', label='S-Learner')\n",
    "plt.plot(cate_t_learner_rf, 'x', label='T-Learner')\n",
    "plt.plot(cate_dr_learner_rf, '+', label='DR-Learner')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: Random Forest: S-Learner, T-Learner, DR-Learner')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/RF-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/RF-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "124bbb212a2ac912",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:05.618459Z",
     "start_time": "2024-05-22T13:09:04.558734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cate_s_learner_rf_train = s_learner_rf.effect(X_train)\n",
    "cate_t_learner_rf_train = t_learner_rf.effect(X_train)\n",
    "cate_dr_learner_rf_train = dr_learner_rf.effect(X_train[features_without_confounders])\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_s_rf_train = cumulative_gain(train_data.assign(cate=cate_s_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_rf_test = cumulative_gain(test_data.assign(cate=cate_s_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_rf_train = cumulative_gain(train_data.assign(cate=cate_t_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_rf_test = cumulative_gain(test_data.assign(cate=cate_t_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_rf_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_rf_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_s_rf_test, color=\"C0\", label=\"S-Learner Test\")\n",
    "plt.plot(gain_curve_s_rf_train, color=\"C1\", label=\"S-Learner Train\")\n",
    "plt.plot(gain_curve_t_rf_test, color=\"C2\", label=\"T-Learner Test\")\n",
    "plt.plot(gain_curve_t_rf_train, color=\"C3\", label=\"T-Learner Train\")\n",
    "plt.plot(gain_curve_dr_rf_test, color=\"C4\", label=\"DR-Learner Test\")\n",
    "plt.plot(gain_curve_dr_rf_train, color=\"C5\", label=\"DR-Learner Train\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain - Random Forest comparison\")\n",
    "plt.savefig(f\"plots/mimic/RF-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/RF-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "2e803ce2a4cfbec8",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Gradient Boosting CATEs comparison",
   "id": "52a7219f51d04efb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:06.196458Z",
     "start_time": "2024-05-22T13:09:05.619811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_s_learner_gb), \"Std Dev:\", np.std(cate_s_learner_gb))\n",
    "print(\"T-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_t_learner_gb), \"Std Dev:\", np.std(cate_t_learner_gb))\n",
    "print(\"DR-Learner - Gradient Boosting - Mean CATE:\", np.mean(cate_dr_learner_gb), \"Std Dev:\", np.std(cate_dr_learner_gb))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_s_learner_gb, 'o', label='S-Learner')\n",
    "plt.plot(cate_t_learner_gb, 'x', label='T-Learner')\n",
    "plt.plot(cate_dr_learner_gb, '+', label='DR-Learner')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: Gradient Boosting: S-Learner, T-Learner, DR-Learner')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/GB-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/GB-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "a27d21567b47cc0f",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:07.001353Z",
     "start_time": "2024-05-22T13:09:06.198107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cate_s_learner_gb_train = s_learner_gb.effect(X_train)\n",
    "cate_t_learner_gb_train = t_learner_gb.effect(X_train)\n",
    "cate_dr_learner_gb_train = dr_learner_gb.effect(X_train[features_without_confounders])\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_s_gb_train = cumulative_gain(train_data.assign(cate=cate_s_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_gb_test = cumulative_gain(test_data.assign(cate=cate_s_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_gb_train = cumulative_gain(train_data.assign(cate=cate_t_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_gb_test = cumulative_gain(test_data.assign(cate=cate_t_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_gb_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_gb_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_s_gb_test, color=\"C0\", label=\"S-Learner Test\")\n",
    "plt.plot(gain_curve_s_gb_train, color=\"C1\", label=\"S-Learner Train\")\n",
    "plt.plot(gain_curve_t_gb_test, color=\"C2\", label=\"T-Learner Test\")\n",
    "plt.plot(gain_curve_t_gb_train, color=\"C3\", label=\"T-Learner Train\")\n",
    "plt.plot(gain_curve_dr_gb_test, color=\"C4\", label=\"DR-Learner Test\")\n",
    "plt.plot(gain_curve_dr_gb_train, color=\"C5\", label=\"DR-Learner Train\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain - Gradient Boosting comparison\")\n",
    "plt.savefig(f\"plots/mimic/GB-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/GB-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "c9990154e5b11a77",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neural Network CATEs comparison",
   "id": "17a7625e43c81173"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:07.432826Z",
     "start_time": "2024-05-22T13:09:07.002308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the mean and standard deviation for CATE estimates from each learner\n",
    "print(\"S-Learner - Neural Network - Mean CATE:\", np.mean(cate_s_learner_nn), \"Std Dev:\", np.std(cate_s_learner_nn))\n",
    "print(\"T-Learner - Neural Network - Mean CATE:\", np.mean(cate_t_learner_nn), \"Std Dev:\", np.std(cate_t_learner_nn))\n",
    "print(\"DR-Learner - Neural Network - Mean CATE:\", np.mean(cate_dr_learner_nn), \"Std Dev:\", np.std(cate_dr_learner_nn))\n",
    "\n",
    "# Create a graph to compare CATE estimates\n",
    "# plt.figure(figsize=(12, 6), dpi=200)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cate_s_learner_nn, 'o', label='S-Learner')\n",
    "plt.plot(cate_t_learner_nn, 'x', label='T-Learner')\n",
    "plt.plot(cate_dr_learner_nn, '+', label='DR-Learner')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('CATE')\n",
    "plt.title('CATE Estimates: Neural Network: S-Learner, T-Learner, DR-Learner')\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/mimic/NN-CATEs.png\")\n",
    "plt.savefig(f\"plots/mimic/NN-CATEs.svg\")\n",
    "plt.show()"
   ],
   "id": "3263a0a18e587982",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:09:08.040708Z",
     "start_time": "2024-05-22T13:09:07.433857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cate_s_learner_nn_train = s_learner_nn.effect(X_train)\n",
    "# cate_t_learner_nn_train = t_learner_nn.effect(X_train)\n",
    "# cate_dr_learner_nn_train = dr_learner_nn.effect(X_train[features_without_confounders])\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "gain_curve_s_nn_train = cumulative_gain(train_data.assign(cate=cate_s_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_s_nn_test = cumulative_gain(test_data.assign(cate=cate_s_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_nn_train = cumulative_gain(train_data.assign(cate=cate_t_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_nn_test = cumulative_gain(test_data.assign(cate=cate_t_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_dr_nn_train = cumulative_gain(train_data.assign(cate=cate_dr_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_dr_nn_test = cumulative_gain(test_data.assign(cate=cate_dr_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "plt.plot(gain_curve_s_nn_test, color=\"C0\", label=\"S-Learner Test\")\n",
    "plt.plot(gain_curve_s_nn_train, color=\"C1\", label=\"S-Learner Train\")\n",
    "plt.plot(gain_curve_t_nn_test, color=\"C2\", label=\"T-Learner Test\")\n",
    "plt.plot(gain_curve_t_nn_train, color=\"C3\", label=\"T-Learner Train\")\n",
    "plt.plot(gain_curve_dr_nn_test, color=\"C4\", label=\"DR-Learner Test\")\n",
    "plt.plot(gain_curve_dr_nn_train, color=\"C5\", label=\"DR-Learner Train\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain - Neural Network comparison\")\n",
    "plt.savefig(f\"plots/mimic/NN-Cumulative_gain.png\")\n",
    "plt.savefig(f\"plots/mimic/NN-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "c2c488e52edd1814",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:12:41.180051Z",
     "start_time": "2024-05-22T13:12:41.073486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "intrp = SingleTreeCateInterpreter(include_model_uncertainty=True, max_depth=2, min_samples_leaf=10)\n",
    "# intrp.interpret(dr_learner_lr, X[features_without_confounders])\n",
    "# intrp.plot(feature_names=[features_without_confounders], fontsize=12)"
   ],
   "id": "158ff8c0efc23183",
   "execution_count": 40,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:26:03.842183Z",
     "start_time": "2024-05-22T13:20:55.635789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shap_values = s_learner_gb.shap_values(X)\n",
    "# local view: explain hetergoeneity for a given observation\n",
    "ind=0\n",
    "shap.plots.force(shap_values[\"mort_28\"][\"peep_regime_high_1.0\"][ind], matplotlib=True)\n",
    "# global view: explain hetergoeneity for a sample of dataset\n",
    "shap.summary_plot(shap_values['mort_28']['peep_regime_high_1.0'])"
   ],
   "id": "b8238dc24146d3bc",
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:29:43.195476Z",
     "start_time": "2024-05-22T13:26:46.320677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shap_values = t_learner_lr.shap_values(X_train)\n",
    "# local view: explain hetergoeneity for a given observation\n",
    "ind=0\n",
    "shap.plots.force(shap_values[\"mort_28\"][\"peep_regime_high_1.0\"][ind], matplotlib=True)\n",
    "# global view: explain hetergoeneity for a sample of dataset\n",
    "shap.summary_plot(shap_values['mort_28']['peep_regime_high_1.0'])"
   ],
   "id": "58f462791e4a2d73",
   "execution_count": 57,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:30:52.966114Z",
     "start_time": "2024-05-22T13:30:51.139384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "shap_values = dr_learner_lr.shap_values(X[features_without_confounders])\n",
    "# local view: explain heterogeneity for a given observation\n",
    "ind=0\n",
    "shap.plots.force(shap_values[\"mort_28\"][\"peep_regime_high_1.0\"][ind], matplotlib=True)\n",
    "# global view: explain hetergoeneity for a sample of dataset\n",
    "shap.summary_plot(shap_values['mort_28']['peep_regime_high_1.0'])"
   ],
   "id": "fd3056c80a89db5b",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T13:30:30.233113Z",
     "start_time": "2024-05-22T13:30:28.947803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shap_values = dr_learner_gb.shap_values(X[features_without_confounders])\n",
    "# local view: explain heterogeneity for a given observation\n",
    "ind=0\n",
    "shap.plots.force(shap_values[\"mort_28\"][\"peep_regime_high_1.0\"][ind], matplotlib=True)\n",
    "# global view: explain heterogeneity for a sample of dataset\n",
    "shap.summary_plot(shap_values['mort_28']['peep_regime_high_1.0'])"
   ],
   "id": "96f3848b2e737e26",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:16:08.851202Z",
     "start_time": "2024-05-22T14:16:08.390379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from nb21 import cumulative_gain, elast, cumulative_gain_inv\n",
    "\n",
    "def cumulative_gain_inv(dataset, prediction, y, t, min_periods=30, steps=100):\n",
    "    size = dataset.shape[0]\n",
    "    ordered_df = dataset.sort_values(prediction, ascending=True).reset_index(drop=True)\n",
    "    n_rows = list(range(min_periods, size, size // steps)) + [size]\n",
    "    return np.array([elast(ordered_df.head(rows), y, t) * (rows / size) for rows in n_rows])\n",
    "\n",
    "# cate_t_learner_rf_train = t_learner_rf.effect(X_train)\n",
    "# cate_t_learner_gb_train = t_learner_gb.effect(X_train)\n",
    "cate_t_learner_lr_train = t_learner_lr.effect(X_train)\n",
    "# cate_t_learner_svm_train = t_learner_svm.effect(X_train)\n",
    "# cate_t_learner_nn_train = t_learner_nn.predict(X_train)\n",
    "\n",
    "\n",
    "train_data = pd.concat([X_train, y_train, t_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test, t_test], axis=1)\n",
    "\n",
    "# gain_curve_t_rf_train = cumulative_gain(train_data.assign(cate=cate_t_learner_rf_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "# gain_curve_t_rf_test = cumulative_gain(test_data.assign(cate=cate_t_learner_rf), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "# gain_curve_t_gb_train = cumulative_gain(train_data.assign(cate=cate_t_learner_gb_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "# gain_curve_t_gb_test = cumulative_gain(test_data.assign(cate=cate_t_learner_gb), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_lr_train = cumulative_gain(train_data.assign(cate=cate_t_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_lr_test = cumulative_gain(test_data.assign(cate=cate_t_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "gain_curve_t_lr_train_inv = cumulative_gain_inv(train_data.assign(cate=cate_t_learner_lr_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "gain_curve_t_lr_test_inv = cumulative_gain_inv(test_data.assign(cate=cate_t_learner_lr), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "# gain_curve_t_svm_train = cumulative_gain(train_data.assign(cate=cate_t_learner_svm_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "# gain_curve_t_svm_test = cumulative_gain(test_data.assign(cate=cate_t_learner_svm), \"cate\", y=outcome_column, t=treatment_column)\n",
    " \n",
    "\n",
    "# gain_curve_t_nn_train = cumulative_gain(train_data.assign(cate=cate_t_learner_nn_train), \"cate\", y=outcome_column, t=treatment_column)\n",
    "# gain_curve_t_nn_test = cumulative_gain(test_data.assign(cate=cate_t_learner_nn), \"cate\", y=outcome_column, t=treatment_column)\n",
    "\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "# plt.plot(gain_curve_t_rf_test, color=\"C0\", label=\"T-Learner Test - Random Forest\")\n",
    "# plt.plot(gain_curve_t_rf_train, color=\"C1\", label=\"T-Learner Train - Random Forest\")\n",
    "# plt.plot(gain_curve_t_gb_test, color=\"C2\", label=\"T-Learner Test - Gradient Boosting\")\n",
    "# plt.plot(gain_curve_t_gb_train, color=\"C3\", label=\"T-Learner Train - Gradient Boosting\")\n",
    "# plt.plot(gain_curve_t_lr_test, color=\"C4\", label=\"T-Learner Test - Linear Regression\")\n",
    "plt.plot(gain_curve_t_lr_train, color=\"C5\", label=\"T-Learner Train - Linear Regression\")\n",
    "# plt.plot(gain_curve_t_lr_test_inv, color=\"C8\", label=\"T-Learner Test - Linear Regression - inv\")\n",
    "plt.plot(gain_curve_t_lr_train_inv, color=\"C9\", label=\"T-Learner Train - Linear Regression - inv\")\n",
    "# plt.plot(gain_curve_t_svm_test, color=\"C6\", label=\"T-Learner Test - SVM\")\n",
    "# plt.plot(gain_curve_t_svm_train, color=\"C7\", label=\"T-Learner Train - SVM\")\n",
    "# plt.plot(gain_curve_t_nn_test, color=\"C6\", label=\"T-Learner Test - Neural Network\")\n",
    "# plt.plot(gain_curve_t_nn_train, color=\"C7\", label=\"T-Learner Train - Neural Network\")\n",
    "plt.plot([0, 100], [0, elast(data, outcome_column, treatment_column)], linestyle=\"--\", color=\"black\", label=\"Baseline\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative gain\")\n",
    "# plt.savefig(f\"plots/mimic/T-Cumulative_gain.png\")\n",
    "# plt.savefig(f\"plots/mimic/T-Cumulative_gain.svg\")\n",
    "plt.show()"
   ],
   "id": "f6d53fd387ef9168",
   "execution_count": 66,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
